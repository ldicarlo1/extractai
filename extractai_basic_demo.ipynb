{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtractAI Notebook (Main / Synchronous)\n",
    "\n",
    "Use this notebook for the standard synchronous workflow:\n",
    "1. Point to a PDF directory\n",
    "2. Specify the model\n",
    "3. Specify max input tokens\n",
    "4. Define prompt + output schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install once in your environment:\n",
    "```bash\n",
    "pip install -e .\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70950249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from datetime import date\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from extractai import (\n",
    "    ExtractAIConfig,\n",
    "    build_prompt,\n",
    "    run_directory_extraction,\n",
    "    save_results_to_csv,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Define output schema and fully user-defined prompt\n",
    "class ExtractedDocument(BaseModel):\n",
    "    summary: str\n",
    "    document_date: date | None = None\n",
    "    category: Literal['Financial', 'Research', 'Government', 'Other']\n",
    "\n",
    "prompt = build_prompt(\n",
    "    \"\"\"\n",
    "    Extract three fields from the document text: summary, document_date, and category.\n",
    "    Document date should be the date the document was published. If not available, return None.\n",
    "    Category must be exactly one of: Financial, Research, Government, Other.\n",
    "    If uncertain, choose the best matching option.\n",
    "    Keep summary concise (2-4 sentences).\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) PDF directory\n",
    "# 2) Model\n",
    "# 3) Max input tokens\n",
    "config = ExtractAIConfig(\n",
    "    pdf_dir='sample_data',\n",
    "    model='gpt-5-nano',\n",
    "    max_input_tokens=5000,\n",
    ")\n",
    "\n",
    "# Optional output directory for CSV export.\n",
    "# Set to None to save in the current working directory.\n",
    "output_dir = 'outputs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = run_directory_extraction(\n",
    "    config=config,\n",
    "    schema=ExtractedDocument,\n",
    "    prompt=prompt,\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(f'=== {result.file_name} === {result.status}')\n",
    "    print(f'Input tokens: {result.input_tokens}')\n",
    "    print()\n",
    "\n",
    "csv_path = save_results_to_csv(results, output_dir=output_dir)\n",
    "print(f'CSV saved to: {csv_path}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
